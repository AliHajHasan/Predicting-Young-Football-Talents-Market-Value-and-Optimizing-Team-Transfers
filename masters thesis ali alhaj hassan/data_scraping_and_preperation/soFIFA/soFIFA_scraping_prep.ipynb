{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SoFIFA web scaping using Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.edge.service import Service as EdgeService\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data scraping using Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Initialize the webdriver and the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Edge WebDriver Path\n",
    "PATH_TO_DRIVER = \"C:/WebDriver/msedgedriver.exe\"  \n",
    "service = EdgeService(PATH_TO_DRIVER)\n",
    "options = webdriver.EdgeOptions()\n",
    "options.add_argument(\"--ignore-certificate-errors\")  \n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--start-maximized\")  \n",
    "\n",
    "# Initialize WebDriver\n",
    "driver = webdriver.Edge(service=service, options=options)\n",
    "driver.maximize_window()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the link and detecting the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sofifa URL with U23 filter\n",
    "base_url = \"https://sofifa.com/players?type=all&lg%5B0%5D=13&lg%5B1%5D=31&lg%5B2%5D=53&lg%5B3%5D=19&lg%5B4%5D=16&aeh=23&showCol%5B%5D=ae&showCol%5B%5D=hi&showCol%5B%5D=wi&showCol%5B%5D=pf&showCol%5B%5D=oa&showCol%5B%5D=pt&showCol%5B%5D=bo&showCol%5B%5D=bp&showCol%5B%5D=gu&showCol%5B%5D=vl&showCol%5B%5D=wg&showCol%5B%5D=ta&showCol%5B%5D=cr&showCol%5B%5D=fi&showCol%5B%5D=he&showCol%5B%5D=sh&showCol%5B%5D=vo&showCol%5B%5D=ts&showCol%5B%5D=dr&showCol%5B%5D=cu&showCol%5B%5D=fr&showCol%5B%5D=lo&showCol%5B%5D=bl&showCol%5B%5D=to&showCol%5B%5D=ac&showCol%5B%5D=sp&showCol%5B%5D=ag&showCol%5B%5D=re&showCol%5B%5D=ba&showCol%5B%5D=tp&showCol%5B%5D=so&showCol%5B%5D=ju&showCol%5B%5D=st&showCol%5B%5D=sr&showCol%5B%5D=ln&showCol%5B%5D=te&showCol%5B%5D=ar&showCol%5B%5D=in&showCol%5B%5D=po&showCol%5B%5D=vi&showCol%5B%5D=pe&showCol%5B%5D=cm&showCol%5B%5D=td&showCol%5B%5D=ma&showCol%5B%5D=sa&showCol%5B%5D=sl&showCol%5B%5D=tg&showCol%5B%5D=gd&showCol%5B%5D=gh&showCol%5B%5D=gc&showCol%5B%5D=gp&showCol%5B%5D=gr&showCol%5B%5D=tt&showCol%5B%5D=bs&showCol%5B%5D=wk&showCol%5B%5D=sk&showCol%5B%5D=aw&showCol%5B%5D=dw&showCol%5B%5D=ir&showCol%5B%5D=bt&showCol%5B%5D=hc&showCol%5B%5D=pac&showCol%5B%5D=sho&offset=\"\n",
    "data = []\n",
    " \n",
    "# Detect Column Names Automatically\n",
    "driver.get(base_url + \"0\")\n",
    "time.sleep(15)  \n",
    "\n",
    "# Extract column headers dynamically\n",
    "headers = driver.find_elements(By.XPATH, \"//thead//th\")\n",
    "columns = [header.text.strip() for header in headers if header.text.strip()]\n",
    "print(\"Detected Columns:\", columns)\n",
    "\n",
    "# Ensure the first column is \"ID\" (Sofifa doesn't label it)\n",
    "if \"ID\" not in columns:\n",
    "    columns.insert(0, \"ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping the data and closing the driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape Player Data\n",
    "for offset in range(0, 65):  # offset is used to scroll through the pages\n",
    "    url = base_url + str(offset * 60)\n",
    "    driver.get(url)\n",
    "    time.sleep(0.8)  # Wait for JavaScript & Cloudflare check\n",
    "\n",
    "    rows = driver.find_elements(By.XPATH, \"//tbody/tr\")\n",
    "\n",
    "    for row in rows:\n",
    "        try:\n",
    "            attributes = row.find_elements(By.XPATH, \".//td\")\n",
    "\n",
    "            player_data = [attr.text.strip() for attr in attributes]\n",
    "\n",
    "            # Ensure data length matches columns\n",
    "            while len(player_data) < len(columns):\n",
    "                player_data.append(None) \n",
    "            player_data = player_data[:len(columns)]  # Trim extra values\n",
    "\n",
    "            data.append(player_data)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row: {e}\")\n",
    "\n",
    "    print(f\"Done for offset {offset}\", end=\"\\r\")\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the data into it's specific directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# Create output folder if needed\n",
    "year = \"2020_2021\"  # Adjust the year as needed\n",
    "year_folder = f\"./{year}\"\n",
    "os.makedirs(year_folder, exist_ok=True)\n",
    "\n",
    "# Save to CSV\n",
    "csv_path = os.path.join(year_folder, 'sofifa_u23_players.csv')\n",
    "df.to_csv(csv_path, encoding='utf-8-sig', index=False)\n",
    "print(\"\\nScraping completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning and organizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converts weight, height, value, wage, and other numerical values properly \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_numeric(value):\n",
    "    if isinstance(value, str):\n",
    "        value = value.strip()\n",
    "        # Extract numbers from height (e.g., \"186cm / 6'1\" -> 186)\n",
    "        if 'cm' in value:\n",
    "            return int(re.search(r'\\d+', value).group())\n",
    "        # Extract numbers from weight (e.g., \"74kg / 163lbs\" -> 74)\n",
    "        elif 'kg' in value:\n",
    "            return int(re.search(r'\\d+', value).group())\n",
    "        # Convert monetary values (e.g., \"€39M\" -> 39000000, \"€89K\" -> 89000)\n",
    "        elif value.startswith('€'):\n",
    "            value = value.replace('€', '')\n",
    "            if 'M' in value:\n",
    "                return int(float(value.replace('M', '')) * 1_000_000)\n",
    "            elif 'K' in value:\n",
    "                return int(float(value.replace('K', '')) * 1_000)\n",
    "        # Remove '+' or '-' sign and any number following it \n",
    "        elif any(sign in value for sign in ['+', '-']):\n",
    "            return int(re.split(r'[+-]', value)[0])\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplifying the position into the one of the four main positions , and fixing the name format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_position(position):\n",
    "    position = position.upper()\n",
    "    if any(pos in position for pos in [\"GK\", \"GOALKEEPER\"]):\n",
    "        return 'G'\n",
    "    elif any(pos in position for pos in [\"CB\", \"LB\", \"RB\", \"LWB\", \"RWB\", \"DEFENDER\"]):\n",
    "        return 'D'\n",
    "    elif any(pos in position for pos in [\"CDM\", \"CM\", \"CAM\",\"LM\",\"RM\", \"MIDFIELDER\"]):\n",
    "        return 'M'\n",
    "    elif any(pos in position for pos in [\"ST\", \"CF\", \"LW\", \"RW\", \"FORWARD\"]):\n",
    "        return 'F'\n",
    "    return position  \n",
    "def extract_name(full_name):\n",
    "    return full_name.split('\\n')[0] if isinstance(full_name, str) else full_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply all needed functions and changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Clean the name column first\n",
    "    df['Name'] = df['Name'].apply(extract_name)\n",
    "    \n",
    "    # Identify numerical columns for selective cleaning\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            try:\n",
    "                df[col] = df[col].apply(clean_numeric)\n",
    "            except:\n",
    "                pass  # Avoid errors on non-numeric columns\n",
    "    \n",
    "    # Simplify position column\n",
    "    df['Best position'] = df['Best position'].apply(simplify_position)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply to our scraped data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = process_dataset(\"./2020_2021/sofifa_u23_players.csv\")\n",
    "df.to_csv(\"./2020_2021/processed_fifa_dataset.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
